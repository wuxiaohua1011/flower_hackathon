{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93eaeaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dataDir = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97531212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'data/dermamnist.npz' with keys: train_images, val_images, test_images, train_labels, val_labels..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dermamnist_file = dataDir / \"dermamnist.npz\"\n",
    "import numpy as np\n",
    "data = np.load(dermamnist_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcbf262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def save_images(sub_dir=\"test\"):\n",
    "    \"\"\"Extract and save test images from dermamnist.npz to data/test directory.\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    data_dir = Path(\"data\")\n",
    "    dermamnist_file = data_dir / \"dermamnist.npz\"\n",
    "    test_dir = data_dir / sub_dir\n",
    "    \n",
    "    # Create test directory if it doesn't exist\n",
    "    test_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load the dataset\n",
    "    print(f\"Loading dataset from {dermamnist_file}\")\n",
    "    data = np.load(dermamnist_file)\n",
    "    \n",
    "    # Print available keys in the dataset\n",
    "    print(f\"Available keys in dataset: {list(data.keys())}\")\n",
    "    \n",
    "    # Extract test data (typically stored as 'test_images' and 'test_labels')\n",
    "    # Let's check what keys are available first\n",
    "    if 'test_images' in data:\n",
    "        test_images = data['test_images']\n",
    "        test_labels = data['test_labels'] if 'test_labels' in data else None\n",
    "    elif 'x_test' in data:\n",
    "        test_images = data['x_test'] \n",
    "        test_labels = data['y_test'] if 'y_test' in data else None\n",
    "    else:\n",
    "        # If we can't find standard keys, look for other possible test data\n",
    "        available_keys = [k for k in data.keys() if isinstance(data[k], np.ndarray)]\n",
    "        print(f\"Available array keys: {available_keys}\")\n",
    "        \n",
    "        # Try to find test data by looking for keys containing 'test' or 'val'\n",
    "        test_keys = [k for k in available_keys if 'test' in k.lower() or 'val' in k.lower()]\n",
    "        if test_keys:\n",
    "            test_images = data[test_keys[0]]\n",
    "            # Look for corresponding labels\n",
    "            label_keys = [k for k in available_keys if 'label' in k.lower() and ('test' in k.lower() or 'val' in k.lower())]\n",
    "            test_labels = data[label_keys[0]] if label_keys else None\n",
    "        else:\n",
    "            # If no test-specific keys found, we might need to split the data\n",
    "            # Let's check if there's a way to identify test data\n",
    "            print(\"No explicit test data found. Available data:\")\n",
    "            for key in available_keys:\n",
    "                print(f\"  {key}: shape {data[key].shape}\")\n",
    "            raise ValueError(f\"Could not find test data in the dataset. Available keys: {list(data.keys())}\")\n",
    "    \n",
    "    print(f\"Test images shape: {test_images.shape}\")\n",
    "    if test_labels is not None:\n",
    "        print(f\"Test labels shape: {test_labels.shape}\")\n",
    "    \n",
    "    # Create subdirectories for each class if labels are available\n",
    "    if test_labels is not None:\n",
    "        unique_labels = np.unique(test_labels)\n",
    "        print(f\"Found {len(unique_labels)} unique classes: {unique_labels}\")\n",
    "        \n",
    "        # Create class subdirectories\n",
    "        for label in unique_labels:\n",
    "            class_dir = test_dir / f\"class_{label}\"\n",
    "            class_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save each image\n",
    "    print(f\"Saving {len(test_images)} test images...\")\n",
    "    \n",
    "    for i, image in enumerate(test_images):\n",
    "        # Convert to PIL Image\n",
    "        # Handle different image formats (grayscale vs RGB)\n",
    "        if len(image.shape) == 2:  # Grayscale\n",
    "            pil_image = Image.fromarray(image, mode='L')\n",
    "        elif len(image.shape) == 3 and image.shape[2] == 1:  # Grayscale with channel dimension\n",
    "            pil_image = Image.fromarray(image.squeeze(), mode='L')\n",
    "        elif len(image.shape) == 3 and image.shape[2] == 3:  # RGB\n",
    "            pil_image = Image.fromarray(image, mode='RGB')\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected image shape {image.shape} for image {i}\")\n",
    "            continue\n",
    "        \n",
    "        # Determine save path\n",
    "        if test_labels is not None:\n",
    "            label = test_labels[i] if test_labels.ndim == 1 else test_labels[i][0]\n",
    "            save_path = test_dir / f\"class_{label}\" / f\"test_image_{i:05d}.png\"\n",
    "        else:\n",
    "            save_path = test_dir / f\"test_image_{i:05d}.png\"\n",
    "        \n",
    "        # Save the image\n",
    "        pil_image.save(save_path)\n",
    "        \n",
    "        # Print progress every 1000 images\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Saved {i + 1}/{len(test_images)} images...\")\n",
    "    \n",
    "    print(f\"Successfully saved all {len(test_images)} test images to {test_dir}\")\n",
    "    \n",
    "    # Print summary\n",
    "    if test_labels is not None:\n",
    "        for label in np.unique(test_labels):\n",
    "            count = np.sum(test_labels == label)\n",
    "            class_dir = test_dir / f\"class_{label}\"\n",
    "            print(f\"Class {label}: {count} images saved to {class_dir}\")\n",
    "    \n",
    "    data.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abbfe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/dermamnist.npz\n",
      "Available keys in dataset: ['train_images', 'val_images', 'test_images', 'train_labels', 'val_labels', 'test_labels']\n",
      "Test images shape: (2005, 28, 28, 3)\n",
      "Test labels shape: (2005, 1)\n",
      "Found 7 unique classes: [0 1 2 3 4 5 6]\n",
      "Saving 2005 test images...\n",
      "Saved 1000/2005 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/ll52nx0s5nx6qsj68m1dw2k80000gn/T/ipykernel_85398/4091061256.py:77: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil_image = Image.fromarray(image, mode='RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000/2005 images...\n",
      "Successfully saved all 2005 test images to data/train\n",
      "Class 0: 66 images saved to data/train/class_0\n",
      "Class 1: 103 images saved to data/train/class_1\n",
      "Class 2: 220 images saved to data/train/class_2\n",
      "Class 3: 23 images saved to data/train/class_3\n",
      "Class 4: 223 images saved to data/train/class_4\n",
      "Class 5: 1341 images saved to data/train/class_5\n",
      "Class 6: 29 images saved to data/train/class_6\n"
     ]
    }
   ],
   "source": [
    "save_images(\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86748ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\n",
      "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from medmnist) (2.2.6)\n",
      "Collecting pandas (from medmnist)\n",
      "  Using cached pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting scikit-learn (from medmnist)\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scikit-image (from medmnist)\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting tqdm (from medmnist)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from medmnist) (11.3.0)\n",
      "Collecting fire (from medmnist)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from medmnist) (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from medmnist) (0.23.0)\n",
      "Collecting termcolor (from fire->medmnist)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from pandas->medmnist) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->medmnist)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->medmnist)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
      "Collecting scipy>=1.11.4 (from scikit-image->medmnist)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from scikit-image->medmnist) (3.5)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->medmnist)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->medmnist)\n",
      "  Downloading tifffile-2025.9.20-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from scikit-image->medmnist) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->medmnist)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->medmnist)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->medmnist)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from torch->medmnist) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from torch->medmnist) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from torch->medmnist) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from torch->medmnist) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from torch->medmnist) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from torch->medmnist) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/flower/lib/python3.12/site-packages (from jinja2->torch->medmnist) (3.0.2)\n",
      "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Using cached pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-macosx_12_0_arm64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:02\u001b[0m0m\n",
      "\u001b[?25hUsing cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: pytz, tzdata, tqdm, tifffile, threadpoolctl, termcolor, scipy, lazy-loader, joblib, imageio, scikit-learn, scikit-image, pandas, fire, medmnist\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [medmnist]\u001b[0m \u001b[32m12/15\u001b[0m [pandas]image]-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed fire-0.7.1 imageio-2.37.0 joblib-1.5.2 lazy-loader-0.4 medmnist-3.0.2 pandas-2.3.2 pytz-2025.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 termcolor-3.1.0 threadpoolctl-3.6.0 tifffile-2025.9.20 tqdm-4.67.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2123818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import DermaMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f205ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19.7M/19.7M [02:49<00:00, 116kB/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = DermaMNIST(split='train', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98016cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
